specVersion: v2
specMinorVersion: 2
meta:
    name: nim-anywhere
    image: project-nim-anywhere
    description: "Enterprise RAG for agri-Culture.click Phase I - DGX Spark Optimized"
    labels:
        - RAG
        - NIM
    createdOn: "2024-05-02T19:47:52Z"
    defaultBranch: main
layout:
    - path: code/
      type: code
      storage: git
    - path: docs/
      type: code
      storage: git
    - path: data/
      type: data
      storage: gitlfs
    - path: data/scratch/
      type: data
      storage: gitignore
environment:
    base:
        registry: nvcr.io
        image: nvidia/ai-workbench/python-cuda122:1.0.3
        build_timestamp: "20231214221614"
        name: Python with CUDA 12.2
        supported_architectures: []
        cuda_version: "12.2"
        description: A Python Base with CUDA 12.2
        entrypoint_script: ""
        labels:
            - cuda12.2
        apps:
            - name: jupyterlab
              type: jupyterlab
              class: webapp
              start_command: jupyter lab --allow-root --port 8888 --ip 0.0.0.0 --no-browser --NotebookApp.base_url=\$PROXY_PREFIX --NotebookApp.default_url=/lab --NotebookApp.allow_origin='*'
              health_check_command: '[ \$(echo url=\$(jupyter lab list | head -n 2 | tail -n 1 | cut -f1 -d'' '' | grep -v ''Currently'' | sed "s@/?@/lab?@g") | curl -o /dev/null -s -w ''%{http_code}'' --config -) == ''200'' ]'
              stop_command: jupyter lab stop 8888
              webapp_options:
                  autolaunch: true
                  port: "8888"
                  proxy:
                      trim_prefix: false
                      url_command: jupyter lab list | head -n 2 | tail -n 1 | cut -f1 -d' ' | grep -v 'Currently'
        programming_languages:
            - python3
        image_version: 1.0.3
        os: linux
        os_distro: ubuntu
        os_distro_release: "22.04"
        schema_version: v2
        package_managers:
            - name: apt
              binary_path: /usr/bin/apt
              installed_packages:
                  - curl
                  - git
                  - git-lfs
                  - python3
                  - gcc
                  - python3-dev
                  - python3-pip
                  - vim
                  - jq
            - name: pip
              binary_path: /usr/local/bin/pip
              installed_packages:
                  - jupyterlab==4.0.7
                  - pydantic==1.10.13
                  - confz==1.6.0
                  - langchain-nvidia-ai-endpoints
    compose_file_path: "docker-compose.yaml"
    variables:
        - name: NVIDIA_LLM_URL
          value: "http://host.docker.internal:8000/v1"
        - name: NVIDIA_EMBED_URL
          value: "http://host.docker.internal:8001/v1"
        - name: LLM_MODEL_NAME
          value: "meta/llama-3.1-8b-instruct"
        - name: EMBEDDING_MODEL_NAME
          value: "nvidia/llama-3.2-nemoretriever-300m-embed-v1"
        - name: NIM_MAX_MODEL_LEN
          value: "16384"
execution:
    apps:
        - name: Visual Studio Code
          type: vs-code
          class: native
        - name: Chat Frontend
          type: custom
          class: webapp
          start_command: export PROXY_PREFIX &&
